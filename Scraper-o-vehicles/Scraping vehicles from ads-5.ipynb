{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODULES USED**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from textblob import TextBlob as tb\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCTION TO SEARCH MOT EXPIRY DATE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mot(s):               ####SOME MOT EXPIRY DATES WERE IN DESCRIPTION AND IN OTHER TEXT### \"a\" is the sentence containg MOT expiry\n",
    "    try:\n",
    "        \n",
    "        if re.search('\\d{2}-\\d{2}-\\d{4}', s):\n",
    "            match = re.search('\\d{2}-\\d{2}-\\d{4}', s)\n",
    "            return datetime.datetime.strptime(match.group(), '%d-%m-%Y').date()\n",
    "        \n",
    "        if re.search('\\d{2}-\\d{4}', s):\n",
    "            match = re.search('\\d{2}-\\d{4}', s)\n",
    "            return datetime.datetime.strptime(match.group(), '%m-%Y').date()      \n",
    "\n",
    "        else:\n",
    "            blob = tb(s[0])\n",
    "            months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "            mot = \"\"\n",
    "            for i in range(len(blob.noun_phrases)):\n",
    "                if blob.noun_phrases[i] == \"mot\":\n",
    "                    for word in blob.noun_phrases[i:]:\n",
    "                        mot = mot + \" \" + word\n",
    "                        if word.lower() in months:\n",
    "                            return mot\n",
    "    except:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIRST FUNCTION THAT SCRAPES THE PAGES AND RETURNs A LIST WITH ALL THE DATA IN IT**\n",
    "\n",
    "SELENIUM OPENS THE THE VEHICLES PAGE AND THEN SETS THE FILTER TO MOST RECENTLY ADDED VEHICLES SO THAT IT'LL BE EASIER TO CHECK THE UPDATED VEHICLES AFTERWARDS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = []              ###A GLOBAL LIST CONTAINING ALL THE SCRAPED DATA###\n",
    "\n",
    "def run_first():           ###FUNCTION THAT SCRAPES THE GIVEN NUMBER OF PAGES###\n",
    "    \n",
    "    driver = webdriver.Chrome('/Users/vaibhav/Downloads/chromedriver')\n",
    "    driver.get('https://www.usedcarsni.com')\n",
    "    sleep(1)\n",
    "\n",
    "    searchbox = driver.find_element_by_xpath('//button[contains(@class, \"submit-search btn btn-warning btn-lg col-xss-12 col-md-4 col-md-push-3 col-lg-4 col-lg-push-4\")]')\n",
    "    searchbox.click()\n",
    "    sleep(1)\n",
    "\n",
    "    button = driver.find_element_by_xpath('/html/body/main/div[4]/nav[1]/div[3]/div/div[1]/span')\n",
    "    button.click()\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "    button = driver.find_element_by_xpath('/html/body/main/div[4]/nav[1]/div[3]/div/div[2]/ul/li[4]/label')\n",
    "    button.click()\n",
    "    \n",
    "    sleep(1)\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    parser = etree.HTMLParser()\n",
    "    tree = etree.fromstring(str(soup), parser)\n",
    "    \n",
    "    s = \"\".join(tree.xpath('//*[contains(@class, \"page-control-label\")]/text()')).split('\\n')\n",
    "    s = \"\".join(s)\n",
    "    number_of_pages = (int(int(s.strip().split(\" \")[-1])/20)) + 1\n",
    "    \n",
    "    pages = input(\"ENTER # OF PAGES TO SCRAPE OR TYPE 'ALL' FOR SCRAPING ALL THE PAGES: \")\n",
    "    \n",
    "    if pages == 'ALL':\n",
    "        pages = number_of_pages\n",
    "\n",
    "    for i in range(int(pages)):\n",
    "        print(\"Page #\" + str(i) + \" out of \" + str(number_of_pages) + \" completed\")\n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "            parser = etree.HTMLParser()\n",
    "            tree = etree.fromstring(str(soup), parser)\n",
    "\n",
    "            for links in tree.xpath('//a[contains(text(), \"More Details\")]/@href'):\n",
    "                temp = []\n",
    "                \n",
    "                temp.append('https://www.usedcarsni.com/' + links)\n",
    "                \n",
    "                r = requests.get('https://www.usedcarsni.com/' + links)\n",
    "                tree = etree.fromstring(r.text, parser)\n",
    "    \n",
    "            ####NAME OF THE VEHICLE\n",
    "                \n",
    "                temp.append(\"\".join(tree.xpath('//*[contains(@class, \"car-name-link\")]/text()')).strip())   \n",
    "    \n",
    "                \n",
    "            ####COLLECTS VALUE OF THE HEADINGS IN THE LIST \"l\"\n",
    "    \n",
    "                l = [\"Mileage\", 'Location', 'Colour', 'Engine Size', 'Fuel Type', 'Transmission', 'Doors', 'Body Style', 'CO2 Emission']\n",
    "\n",
    "                for i in l:\n",
    "                    x = '//*[contains(@class, \"technical-headers\") and contains(text(),\"'\n",
    "                    w =  i\n",
    "                    y = '\")]/following-sibling::div/text()'\n",
    "                    s = x+w+y\n",
    "                    temp.append(\"\".join(tree.xpath(s)))          \n",
    "        \n",
    "                \n",
    "            ####Collects MOT date\n",
    "                \n",
    "                if tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(),\"MOT Expiry\")]/following-sibling::div/text()'):\n",
    "                    temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(),\"MOT Expiry\")]/following-sibling::div/text()')))\n",
    "        \n",
    "                else:\n",
    "                    a = tree.xpath('//*[contains(text(), \"MOT\")]/text()')\n",
    "                    MOT = mot(a)\n",
    "                    temp.append(MOT)\n",
    "                \n",
    "            ####TAX COST VALUE\n",
    "                \n",
    "                temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Tax Cost\")]/following-sibling::div/a/text()')))\n",
    "                \n",
    "            ####INSURANCE\n",
    "                \n",
    "                temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Insurance\")]/following-sibling::div/a[1]/text()')))\n",
    "                \n",
    "            ####SELLER TYPE(DEALER OR PRIVATE)\n",
    "                \n",
    "                if tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Seller\")]/following-sibling::div/span/text()'):\n",
    "                    temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Seller\")]/following-sibling::div/span/text()')))    \n",
    "                else:\n",
    "                    temp.append('Dealer')\n",
    "            \n",
    "            #####DESCRIPTION\n",
    "            \n",
    "                temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-info features-text\")]/text()')[0]))\n",
    "                \n",
    "            ####CAR PRICE\n",
    "                \n",
    "                temp.append(\"\".join(tree.xpath('//*[contains(@class, \"row technical-textarea car-price-box\")]/div[2]/div/span/text()')))\n",
    "    \n",
    "                main.append(temp)\n",
    "    \n",
    "            \n",
    "        ####CLICKS ON THE NEXT PAGE\n",
    "    \n",
    "            button = driver.find_element_by_xpath('//li[contains(@class, \"active\")]/following-sibling::li[1]/a')\n",
    "            button.click()\n",
    "            sleep(1)\n",
    "        except:\n",
    "            pass\n",
    "    driver.close()\n",
    "    return main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_first_page():\n",
    "    driver = webdriver.Chrome('/Users/vaibhav/Downloads/chromedriver')\n",
    "    driver.get('https://www.usedcarsni.com')\n",
    "    sleep(1)\n",
    "\n",
    "    searchbox = driver.find_element_by_xpath('//button[contains(@class, \"submit-search btn btn-warning btn-lg col-xss-12 col-md-4 col-md-push-3 col-lg-4 col-lg-push-4\")]')\n",
    "    searchbox.click()\n",
    "    sleep(1)\n",
    "\n",
    "    button = driver.find_element_by_xpath('/html/body/main/div[4]/nav[1]/div[3]/div/div[1]/span')\n",
    "    button.click()\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "    button = driver.find_element_by_xpath('/html/body/main/div[4]/nav[1]/div[3]/div/div[2]/ul/li[4]/label')\n",
    "    button.click()\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMOVING UNWANTED \"\\n\" FROM OUR DATA, UPDATE CHECK FUNCTION AND SECOND FUNCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_n(column):\n",
    "    col = []\n",
    "    for value in df[column]:\n",
    "        col.append(\"\".join(value.split('\\n')))\n",
    "    df[column] = col\n",
    "    \n",
    "    \n",
    "def update(details, data):               \n",
    "    temp = []\n",
    "    \n",
    "    temp.append('https://www.usedcarsni.com/' + details)\n",
    "                \n",
    "    r = requests.get('https://www.usedcarsni.com/' + details)\n",
    "    parser = etree.HTMLParser()\n",
    "    tree = etree.fromstring(r.text, parser)\n",
    "    \n",
    "    temp.append(\"\".join(tree.xpath('//*[contains(@class, \"car-name-link\")]/text()')))\n",
    "    \n",
    "    l = [\"Mileage\", 'Location', 'Colour', 'Engine Size', 'Fuel Type', 'Transmission', 'Doors', 'Body Style', 'CO2 Emission']\n",
    "\n",
    "    for i in l:\n",
    "        x = '//*[contains(@class, \"technical-headers\") and contains(text(),\"'\n",
    "        w =  i\n",
    "        y = '\")]/following-sibling::div/text()'\n",
    "        s = x+w+y\n",
    "        temp.append(\"\".join(tree.xpath(s)))\n",
    "        \n",
    "    \n",
    "    if tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(),\"MOT Expiry\")]/following-sibling::div/text()'):\n",
    "        temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(),\"MOT Expiry\")]/following-sibling::div/text()')))\n",
    "        \n",
    "    else:\n",
    "        a = tree.xpath('//*[contains(text(), \"MOT\")]/text()')\n",
    "        MOT = mot(a)\n",
    "        temp.append(MOT)\n",
    "        \n",
    "    temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Tax Cost\")]/following-sibling::div/a/text()')))\n",
    "    temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Insurance\")]/following-sibling::div/a[1]/text()')))\n",
    "    if tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Seller\")]/following-sibling::div/span/text()'):\n",
    "        temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-headers\") and contains(text(), \"Seller\")]/following-sibling::div/span/text()')))    \n",
    "    else:\n",
    "        temp.append('Dealer')\n",
    "            \n",
    "    temp.append(\"\".join(tree.xpath('//*[contains(@class, \"technical-info features-text\")]/text()')[0]))\n",
    "    temp.append(\"\".join(tree.xpath('//*[contains(@class, \"row technical-textarea car-price-box\")]/div[2]/div/span/text()')))\n",
    "    \n",
    "    data = data.insert(0, temp)\n",
    "    temp = []\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update_check(driver, df, data):\n",
    "    curr_page = driver.page_source\n",
    "    soup = BeautifulSoup(curr_page, 'lxml')\n",
    "    parser = etree.HTMLParser()\n",
    "    tree = etree.fromstring(str(soup), parser)\n",
    "    details = tree.xpath('//a[contains(text(), \"More Details\")]/@href')\n",
    "    for i in range(1,21):\n",
    "        x = \"\".join(tree.xpath('/html/body/main/div[4]/div[4]/div/article[' + str(i) + ']/div[3]/div[1]/a/p/strong/span/text()'))\n",
    "        y = \"\".join(tree.xpath('/html/body/main/div[4]/div[4]/div/article[' + str(i) + ']/div[3]/div[1]/a/p/strong/text()'))\n",
    "        x = x.split('\\n')\n",
    "        y = y.split('\\n')\n",
    "        x = \"\".join(x)\n",
    "        y = \"\".join(y)\n",
    "        z = x.strip() +\" \"+ y.strip()\n",
    "        \n",
    "        if \"\".join(df['Vehicle Name'][0].split(\" \")) == \"\".join(z.split(\" \")):\n",
    "            return data\n",
    "            \n",
    "        elif \"\".join(df['Vehicle Name'][0].split(\" \")) != \"\".join(z.split(\" \")):\n",
    "            print(\"DataFrame: \"+ df['Vehicle Name'][0])\n",
    "            print(\"Checking with: \" + z)\n",
    "            update(details[i-1], data)\n",
    "        \n",
    "        \n",
    "    button = driver.find_element_by_xpath('//li[contains(@class, \"active\")]/following-sibling::li[1]/a')\n",
    "    button.click()\n",
    "    return update_check(driver, df, data)\n",
    "\n",
    "def run_second(time_to_run_update, iterations, df, data):\n",
    "\n",
    "    wakeup = time.time()\n",
    "    i=0\n",
    "    while i<iterations:\n",
    "        wakeup += time_to_run_update\n",
    "        print('start')\n",
    "        \n",
    "        driver = open_first_page()\n",
    "        \n",
    "        u = update_check(driver, df, data)\n",
    " \n",
    "        while time.time()<wakeup:\n",
    "            time.sleep(1)\n",
    "    \n",
    "        i = i+1\n",
    "        driver.close()\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN THE NEXT CELL TO START SCRAPING THE CURRENTLY AVAILABLE VEHICLES ON THE SITE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = run_first()        ###WILL SCRAPE ALL THE CURRENTLY AVAILABLE PAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREATING DATAFRAME**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"URL\", \"Vehicle Name\", \"Mileage\", 'Location', 'Colour', 'Engine Size', 'Fuel Type', 'Transmission', 'Doors', 'Body Style', 'CO2 Emission', 'MOT Expiry', 'Tax Cost', 'Insurance', 'Seller', 'Description', 'Price']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "remove_n('Insurance')\n",
    "remove_n('Tax Cost')\n",
    "remove_n('Description')\n",
    "remove_n('Vehicle Name')\n",
    "print(len(data))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN THE NEXT CELL TO CHECK IF ANY NEW VEHICLE HAS BEEN ADDED TO THE LIST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = input(\"Time to check for updates again: \")\n",
    "iterations = input(\"No. of times you want to check for updates: \")\n",
    "u = run_second(int(t), int(iterations), df, data)      ###WILL CHECK FOR UPDATES AFTER EVERY \"\"time\"\" SECONDS for \"\"iterations\"\" times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"URL\", \"Vehicle Name\", \"Mileage\", 'Location', 'Colour', 'Engine Size', 'Fuel Type', 'Transmission', 'Doors', 'Body Style', 'CO2 Emission', 'MOT Expiry', 'Tax Cost', 'Insurance', 'Seller', 'Description', 'Price']\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "remove_n('Insurance')\n",
    "remove_n('Tax Cost')\n",
    "remove_n('Description')\n",
    "remove_n('Vehicle Name')\n",
    "print(len(data))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENTER THE PATH WHERE YOU WANT TO STORE THE COMPLETE SCRAPED CSV FILE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = input(\"Enter path you want to store your file: \")\n",
    "df.to_csv(path)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
