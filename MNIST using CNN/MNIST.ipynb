{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPool2D, AvgPool2D\n",
    "\n",
    "# optimizer, data generator and learning rate reductor\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USING ONLY DENSE LAYERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.4836 - acc: 0.8269\n",
      "log: {'loss': 0.4835913896481196, 'acc': 0.82695}\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.3648 - acc: 0.8669\n",
      "log: {'loss': 0.36480052959521614, 'acc': 0.86695}\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.3256 - acc: 0.8796\n",
      "log: {'loss': 0.3255963470419248, 'acc': 0.8796}\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "[0.3698438768386841, 0.8671]\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):                   #on_epoch_end is called when an epoch ends, if the name of function is changed then it won't work\n",
    "        print(\"log: \" + str(logs))\n",
    "        if(logs.get('loss')<0.2):\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "def load_data():\n",
    "    fashion_mnist = keras.datasets.fashion_mnist\n",
    "    return fashion_mnist.load_data()\n",
    "    \n",
    "def create_model():\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256,activation=tf.nn.relu),\n",
    "    #keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate__model(model, trainx, trainy, testx, testy):\n",
    "    model.fit(trainx, trainy,epochs=3, callbacks = [callbacks])\n",
    "    print(model.evaluate(testx, testy))\n",
    "    \n",
    "(trainx, trainy), (testx, testy) = load_data()\n",
    "trainx = np.array(trainx)/255.0\n",
    "testx = np.array(testx)/255.0\n",
    "model = None\n",
    "model = create_model()\n",
    "train_and_evaluate__model(model, trainx, trainy, testx, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADDING 1 CONVOLUTION LAYER AND 1 MAXPOOLING LAYER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 234s 6ms/step - loss: 0.1760 - accuracy: 0.9468\n",
      "log: {'loss': 0.1759790851147402, 'accuracy': 0.9467857}\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 242s 6ms/step - loss: 0.0587 - accuracy: 0.9818\n",
      "log: {'loss': 0.058706330619220225, 'accuracy': 0.98183334}\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 251s 6ms/step - loss: 0.0460 - accuracy: 0.9859\n",
      "log: {'loss': 0.0460444989808436, 'accuracy': 0.98590475}\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 261s 6ms/step - loss: 0.0388 - accuracy: 0.9875\n",
      "log: {'loss': 0.03883004041539417, 'accuracy': 0.98754764}\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 270s 6ms/step - loss: 0.0355 - accuracy: 0.9885\n",
      "log: {'loss': 0.03546970651156846, 'accuracy': 0.9885}\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 274s 7ms/step - loss: 0.0313 - accuracy: 0.9900\n",
      "log: {'loss': 0.03128993932082362, 'accuracy': 0.9900238}\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 271s 6ms/step - loss: 0.0311 - accuracy: 0.9904\n",
      "log: {'loss': 0.031120831196329423, 'accuracy': 0.99038094}\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 270s 6ms/step - loss: 0.0265 - accuracy: 0.9919\n",
      "log: {'loss': 0.02652929589334166, 'accuracy': 0.99188095}\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 270s 6ms/step - loss: 0.0266 - accuracy: 0.9919\n",
      "log: {'loss': 0.026612210431346848, 'accuracy': 0.9919286}\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 271s 6ms/step - loss: 0.0254 - accuracy: 0.9920\n",
      "log: {'loss': 0.025409610767094862, 'accuracy': 0.9919762}\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 281s 7ms/step - loss: 0.0210 - accuracy: 0.9932\n",
      "log: {'loss': 0.021045381059404462, 'accuracy': 0.9932381}\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 271s 6ms/step - loss: 0.0195 - accuracy: 0.9937\n",
      "log: {'loss': 0.019509636359998868, 'accuracy': 0.9936905}\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 272s 6ms/step - loss: 0.0180 - accuracy: 0.9946\n",
      "log: {'loss': 0.017976785039423876, 'accuracy': 0.99457145}\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 261s 6ms/step - loss: 0.0162 - accuracy: 0.9946\n",
      "log: {'loss': 0.016223888748092576, 'accuracy': 0.99457145}\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 253s 6ms/step - loss: 0.0170 - accuracy: 0.9946\n",
      "log: {'loss': 0.01702211835301326, 'accuracy': 0.9946191}\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 256s 6ms/step - loss: 0.0150 - accuracy: 0.9953\n",
      "log: {'loss': 0.014956487114635474, 'accuracy': 0.9952857}\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 268s 6ms/step - loss: 0.0118 - accuracy: 0.9958\n",
      "log: {'loss': 0.011799193347424512, 'accuracy': 0.9958095}\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 259s 6ms/step - loss: 0.0124 - accuracy: 0.9964\n",
      "log: {'loss': 0.012386479785161403, 'accuracy': 0.99640477}\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 255s 6ms/step - loss: 0.0121 - accuracy: 0.9960\n",
      "log: {'loss': 0.012071341335138727, 'accuracy': 0.99602383}\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 261s 6ms/step - loss: 0.0119 - accuracy: 0.9962\n",
      "log: {'loss': 0.011879800174812166, 'accuracy': 0.99616665}\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):                   #on_epoch_end is called when an epoch ends, if the name of function is changed then it won't work\n",
    "        print(\"log: \" + str(logs))\n",
    "        if(logs.get('loss')<0.0001):\n",
    "            #print(\"\\nReached 80% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"/Users/vaibhav/Downloads/train.csv\")\n",
    "trainy = train['label']\n",
    "trainx = train.drop(\"label\", axis=1)\n",
    "\n",
    "testx = pd.read_csv(\"/Users/vaibhav/Downloads/test.csv\")\n",
    "    \n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = 3, activation='relu', input_shape = (28,28,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size = 3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size = 4, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=tf.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate__model(model, trainX, trainY, testX):\n",
    "    model.fit(trainX, trainY,epochs=20, callbacks = [callbacks], batch_size=64)\n",
    "    #print(model.evaluate(x=testX, y=testY))\n",
    "    predictions = model.predict(testX)\n",
    "    \n",
    "\n",
    "trainx = trainx.values.reshape(42000,28,28,1)           #for convolution layer(it expects everything in single tensor[4-d] and not 60000 images as a list in dense layer)\n",
    "testx = testx.values.reshape(28000,28,28,1)             #for convolution layer\n",
    "\n",
    "\n",
    "#one hot encoder label\n",
    "trainy = to_categorical(trainy, num_classes = 10)\n",
    "\n",
    "#trainX, testX, trainY, testY = train_test_split(trainx, trainy, test_size = 0.1)\n",
    "\n",
    "#normalisation\n",
    "trainx = np.array(trainx)/255.0\n",
    "testx = np.array(testx)/255.0\n",
    "model = None\n",
    "model = create_model()\n",
    "train_and_evaluate__model(model, trainx, trainy, testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageId = []\n",
    "for i in range(1, 28001):\n",
    "    ImageId.append(i)\n",
    "df = pd.DataFrame(columns = {\"ImageId\"}, data = ImageId)\n",
    "df[\"Label\"] = predictions\n",
    "df.to_csv(\"/Users/vaibhav/Downloads/predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
